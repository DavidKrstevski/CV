{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe5c551b7238efb",
   "metadata": {},
   "source": [
    "UTKFace Age-Prediction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a543164c437e861",
   "metadata": {},
   "source": [
    "Imports & Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "ba3dcdc283ced024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:10:33.311372Z",
     "start_time": "2025-10-30T19:10:28.010768Z"
    }
   },
   "source": [
    "# === Imports & Global Settings (TensorFlow-first, with safe fallbacks) ===\n",
    "import os, sys, atexit, math, random, logging, pickle, gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from matplotlib.container import BarContainer\n",
    "\n",
    "# -- TensorFlow + Keras (prefer tf.keras; fall back to standalone Keras only if needed)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, models, regularizers, callbacks\n",
    "    from tensorflow.keras.models import load_model\n",
    "    USING_TF_KERAS = True\n",
    "except ModuleNotFoundError:\n",
    "    # Fallback (rare on TF 2.16+, but harmless)\n",
    "    import tensorflow as tf  # keep TF for seeding and device control if available\n",
    "    import keras\n",
    "    from keras import layers, models, regularizers, callbacks\n",
    "    from keras.models import load_model\n",
    "    USING_TF_KERAS = False\n",
    "\n",
    "# --- Reproducibility ---\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "try:\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "except Exception:\n",
    "    # In case TF fails at runtime for some reason, don’t crash the notebook\n",
    "    pass\n",
    "\n",
    "# --- Plot style ---\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "rosa_palette = [\"#F9C5D5\", \"#F7A1C4\", \"#F48FB1\", \"#F06292\", \"#EC407A\"]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "bee0d4236f4edfd0",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "60ef119ebf6cf3f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:14:47.183330Z",
     "start_time": "2025-10-30T19:10:38.752540Z"
    }
   },
   "source": [
    "def load_utkface_dataset(image_dir=\"./data/images\"):\n",
    "    images, labels = [], []\n",
    "    all_files = os.listdir(image_dir)\n",
    "    random.shuffle(all_files)\n",
    "    max_images = 24108                     # full UTKFace size\n",
    "\n",
    "    for file_name in all_files[:max_images]:\n",
    "        name = os.path.splitext(file_name)[0].replace(\".chip\", \"\")\n",
    "        parts = name.split(\"_\")\n",
    "        if len(parts) != 4 or any(p == \"\" for p in parts):\n",
    "            continue\n",
    "        try:\n",
    "            age, gender, race = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "            date = parts[3]\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if not (0 <= age <= 116 and gender in (0, 1) and 0 <= race <= 4 and len(date) == 17):\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(image_dir, file_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read: {file_name}\")\n",
    "            continue\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if img.ndim != 3 or img.shape[2] != 3:\n",
    "            print(f\"Unexpected format for: {file_name}, shape={img.shape}\")\n",
    "            continue\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append({\"age\": age, \"gender\": gender, \"race\": race, \"datetime\": date})\n",
    "\n",
    "    print(f\"Loaded {len(images)} valid images out of {len(all_files)} files.\")\n",
    "\n",
    "    df = pd.DataFrame(labels)\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(f\"Total images: {len(df)}\")\n",
    "    print(f\"Age range: {df['age'].min()} - {df['age'].max()} (mean: {df['age'].mean():.1f})\")\n",
    "    print(f\"Gender distribution:\\n{df['gender'].value_counts()}\")\n",
    "    print(f\"Race distribution:\\n{df['race'].value_counts()}\")\n",
    "    print(f\"Average image size (HxW): {np.mean([img.shape[:2] for img in images], axis=0).astype(int)}\")\n",
    "\n",
    "    return images, labels, df\n",
    "\n",
    "# Load the data\n",
    "images, labels, df = load_utkface_dataset(\"./data/images\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24099 valid images out of 24108 files.\n",
      "\n",
      "=== Dataset Summary ===\n",
      "Total images: 24099\n",
      "Age range: 1 - 116 (mean: 33.0)\n",
      "Gender distribution:\n",
      "gender\n",
      "0    12578\n",
      "1    11521\n",
      "Name: count, dtype: int64\n",
      "Race distribution:\n",
      "race\n",
      "0    10220\n",
      "1     4556\n",
      "3     4027\n",
      "2     3585\n",
      "4     1711\n",
      "Name: count, dtype: int64\n",
      "Average image size (HxW): [662 637]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9d03854e827e788a",
   "metadata": {},
   "source": [
    "Visualisation Helpers"
   ]
  },
  {
   "cell_type": "code",
   "id": "5056b17ae9f4521a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:15:30.472748Z",
     "start_time": "2025-10-30T19:15:30.369412Z"
    }
   },
   "source": [
    "def plot_random_samples(images, labels, gender_map, race_map):\n",
    "    # Show 9 random images with age/gender/race caption\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, idx in enumerate(random.sample(range(len(images)), min(9, len(images)))):\n",
    "        img = images[idx]\n",
    "        label = labels[idx]\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\n",
    "            f'Age: {label[\"age\"]}\\n'\n",
    "            f'Gender: {gender_map.get(label.get(\"gender\"), label.get(\"gender\"))} '\n",
    "            f'Race: {race_map.get(label.get(\"race\"), label.get(\"race\"))}',\n",
    "            fontsize=10, color=\"#4A4A4A\"\n",
    "        )\n",
    "    plt.suptitle(\"Random Sample of UTKFace Images\", fontsize=14, weight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_distribution_charts(df):\n",
    "    # Age histogram + gender / race bar-plots + box-plots\n",
    "\n",
    "    # Age\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df[\"age\"], color=\"#F48FB1\", kde=True)\n",
    "    plt.title('Age Distribution', fontsize=14, weight='bold')\n",
    "    plt.xlabel('Age'); plt.ylabel('Frequency')\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Gender\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    ax = sns.countplot(data=df, x=\"gender\", hue=\"gender\",\n",
    "                       palette=[\"#F9C5D5\", \"#F48FB1\"], legend=False)\n",
    "    for c in ax.containers:\n",
    "        if isinstance(c, BarContainer):\n",
    "            ax.bar_label(c, fmt='%d', fontsize=10)\n",
    "    plt.title(\"Gender Balance\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Gender\"); plt.ylabel(\"Count\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Race\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    ax = sns.countplot(data=df, x=\"race\", hue=\"race\", palette=rosa_palette, legend=False)\n",
    "    for c in ax.containers:\n",
    "        if isinstance(c, BarContainer):\n",
    "            ax.bar_label(c, fmt='%d', fontsize=10)\n",
    "    plt.title(\"Race Balance\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Race\"); plt.ylabel(\"Count\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Age by gender\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(data=df, x=\"gender\", y=\"age\", hue=\"gender\",\n",
    "                palette=[\"#F9C5D5\", \"#F48FB1\"], legend=False, showfliers=True)\n",
    "    plt.title(\"Age Distribution by Gender\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Gender\"); plt.ylabel(\"Age\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Age by race\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.boxplot(data=df, x=\"race\", y=\"age\", hue=\"race\",\n",
    "                palette=rosa_palette, legend=False, showfliers=True)\n",
    "    plt.title(\"Age Distribution by Race\", fontsize=14, weight='bold')\n",
    "    plt.xlabel(\"Race\"); plt.ylabel(\"Age\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_age_bin_distribution(bins_train, bins_val, bins_test, AGE_BINS, rosa_palette=None):\n",
    "    #Bar-plots (counts & %) of stratified age-bin splits\n",
    "    if rosa_palette is None:\n",
    "        rosa_palette = [\"#F9C5D5\", \"#F48FB1\", \"#EC407A\"]\n",
    "    K = len(AGE_BINS) - 1\n",
    "    bin_labels = [f\"{AGE_BINS[i]}–{AGE_BINS[i+1]-1}\" if i < K-1 else f\"{AGE_BINS[i]}+\"\n",
    "                  for i in range(K)]\n",
    "\n",
    "    def counts_in_order(counter, K):\n",
    "        return np.array([counter.get(i, 0) for i in range(K)], dtype=np.int32)\n",
    "\n",
    "    train_c = counts_in_order(Counter(bins_train), K)\n",
    "    val_c   = counts_in_order(Counter(bins_val),   K)\n",
    "    test_c  = counts_in_order(Counter(bins_test),  K)\n",
    "\n",
    "    x = np.arange(K); w = 0.25\n",
    "\n",
    "    # counts\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.bar(x-w, train_c, width=w, label=\"Train\", color=rosa_palette[0])\n",
    "    plt.bar(x,   val_c,   width=w, label=\"Val\",   color=rosa_palette[1])\n",
    "    plt.bar(x+w, test_c,  width=w, label=\"Test\",  color=rosa_palette[2])\n",
    "    plt.xticks(x, bin_labels, rotation=0, fontsize=11)\n",
    "    plt.xlabel(\"Age Bins\"); plt.ylabel(\"Count\")\n",
    "    plt.title(\"Age-bin Distribution (Counts)\", weight=\"bold\")\n",
    "    plt.legend(); plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # percentages\n",
    "    train_p = train_c/train_c.sum()*100\n",
    "    val_p   = val_c/val_c.sum()*100\n",
    "    test_p  = test_c/test_c.sum()*100\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.bar(x-w, train_p, width=w, label=\"Train\", color=rosa_palette[0])\n",
    "    plt.bar(x,   val_p,   width=w, label=\"Val\",   color=rosa_palette[1])\n",
    "    plt.bar(x+w, test_p,  width=w, label=\"Test\",  color=rosa_palette[2])\n",
    "    plt.xticks(x, bin_labels, rotation=0, fontsize=11)\n",
    "    plt.xlabel(\"Age Bins\"); plt.ylabel(\"Share (%)\")\n",
    "    plt.title(\"Age-bin Distribution (Percent)\", weight=\"bold\")\n",
    "    for i,(tp,vp,sp) in enumerate(zip(train_p,val_p,test_p)):\n",
    "        plt.text(i-w, tp+0.5, f\"{tp:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(i,   vp+0.5, f\"{vp:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(i+w, sp+0.5, f\"{sp:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.legend(); plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "def plot_avg_sample_weight_per_bin(train_weights, bins_train, AGE_BINS, bar_color=\"#EC407A\"):\n",
    "    # Average inverse-frequency weight per age bin\n",
    "    unique = sorted(set(bins_train))\n",
    "    avg_w  = [train_weights[np.array(bins_train)==b].mean() for b in unique]\n",
    "    bin_labels = [f\"{AGE_BINS[i]}–{AGE_BINS[i+1]-1}\" if i<len(AGE_BINS)-2 else f\"{AGE_BINS[i]}+\"\n",
    "                  for i in unique]\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(bin_labels, avg_w, color=bar_color, alpha=0.8, edgecolor=\"white\", linewidth=1.2)\n",
    "    plt.xlabel(\"Age Bins\"); plt.ylabel(\"Average Sample Weight\")\n",
    "    plt.title(\"Inverse-Frequency Sample Weights per Age Bin\", weight=\"bold\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "    for i,v in enumerate(avg_w):\n",
    "        plt.text(i, v+max(avg_w)*0.02, f\"{v:.2f}\", ha='center', va='bottom', fontsize=9)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "def plot_augmented_samples(batch_X, batch_y_raw, n_rows=2, n_cols=4, title=\"Augmented Sample Previews\"):\n",
    "    # Grid of augmented images with raw age label\n",
    "    fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                             figsize=(n_cols*2.5, n_rows*2.5), constrained_layout=True)\n",
    "    fig.suptitle(title, fontsize=14, weight=\"bold\", y=1.02)\n",
    "    for ax, img, age in zip(axes.ravel(), batch_X, batch_y_raw):\n",
    "        ax.imshow(np.clip(img,0,1))\n",
    "        ax.set_title(f\"Age: {int(age)}\", fontsize=10, pad=4)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, title_suffix=\"\"):\n",
    "    # Loss & MAE curves\n",
    "    plt.figure(figsize=(14,6))\n",
    "    train_c, val_c = \"#F48FB1\", \"#F9C5D5\"\n",
    "\n",
    "    # loss\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss', color=train_c, linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss', color=val_c, linewidth=2)\n",
    "    plt.title(f'Loss Curve {title_suffix}', weight='bold')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Huber Loss')\n",
    "    plt.legend(); plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    # MAE\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['mae'], label='Train MAE', color=train_c, linewidth=2)\n",
    "    plt.plot(history.history['val_mae'], label='Val MAE', color=val_c, linewidth=2)\n",
    "    plt.title(f'MAE Curve {title_suffix}', weight='bold')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('MAE')\n",
    "    plt.legend(); plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout(); plt.show()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8b4ac08be3f20e0f",
   "metadata": {},
   "source": [
    "Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ce5cc9e8f2df1fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:15:36.698306Z",
     "start_time": "2025-10-30T19:15:36.667491Z"
    }
   },
   "source": [
    "# Global objects, will be set from preprocessing\n",
    "rng = None\n",
    "NORMALIZE_01 = True\n",
    "\n",
    "def set_augment_seed(random_generator, normalize=True):\n",
    "    # Inject RNG and normalisation flag\n",
    "    global rng, NORMALIZE_01\n",
    "    rng = random_generator\n",
    "    NORMALIZE_01 = normalize\n",
    "\n",
    "\n",
    "def random_hflip(img, p=0.5):\n",
    "    if rng.random() < p:\n",
    "        return np.ascontiguousarray(img[:, ::-1, :])\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_rotate(img, max_deg=10):\n",
    "    deg = float(rng.uniform(-max_deg, max_deg))\n",
    "    h, w = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), deg, 1.0)\n",
    "    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR,\n",
    "                         borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "\n",
    "def random_crop_and_resize(img, scale=(0.88, 1.0)):\n",
    "    h, w = img.shape[:2]\n",
    "    s = float(rng.uniform(scale[0], scale[1]))\n",
    "    new_h, new_w = int(h*s), int(w*s)\n",
    "    max_y = max(h - new_h, 0)\n",
    "    max_x = max(w - new_w, 0)\n",
    "    y0 = int(rng.integers(0, max_y+1)) if max_y>0 else 0\n",
    "    x0 = int(rng.integers(0, max_x+1)) if max_x>0 else 0\n",
    "    crop = img[y0:y0+new_h, x0:x0+new_w, :]\n",
    "    return cv2.resize(crop, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "def random_brightness_contrast(img, b_lim=0.15, c_lim=0.15, p=0.8):\n",
    "    if rng.random() > p:\n",
    "        return img\n",
    "    brightness = float(rng.uniform(-b_lim, b_lim))\n",
    "    contrast = 1.0 + float(rng.uniform(-c_lim, c_lim))\n",
    "    out = img * contrast + brightness\n",
    "    return np.clip(out, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def add_gaussian_noise(img, sigma=0.02, p=0.3):\n",
    "    if rng.random() > p:\n",
    "        return img\n",
    "    noise = rng.normal(0.0, sigma, img.shape).astype(np.float32)\n",
    "    out = img + noise\n",
    "    return np.clip(out, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def augment_once(img_uint8):\n",
    "    y = random_hflip(img_uint8, p=0.5)\n",
    "    y = random_rotate(y, max_deg=10)\n",
    "    y = random_crop_and_resize(y, scale=(0.88, 1.0))\n",
    "    y = y.astype(np.float32) / 255.0 if NORMALIZE_01 else y.astype(np.float32)\n",
    "    y = random_brightness_contrast(y, b_lim=0.15, c_lim=0.15, p=0.8)\n",
    "    y = add_gaussian_noise(y, sigma=0.02, p=0.3)\n",
    "    return y"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "90ff1587983d2c41",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "2289e32fd7949c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:15:42.718698Z",
     "start_time": "2025-10-30T19:15:42.679914Z"
    }
   },
   "source": [
    "def preprocess_images_to_memmap(images, labels, target_size=(160,160),\n",
    "                               save_X_path=None, save_y_path=None):\n",
    "\n",
    "    if save_X_path is None or save_y_path is None:\n",
    "        raise ValueError(\"Must provide save_X_path and save_y_path\")\n",
    "    os.makedirs(os.path.dirname(save_X_path), exist_ok=True)\n",
    "\n",
    "    n = len(images)\n",
    "    w, h = target_size\n",
    "    print(f\"Writing memmap files ({w}x{h}) ... (n={n})\")\n",
    "\n",
    "    if os.path.exists(save_X_path) and os.path.exists(save_y_path):\n",
    "        print(f\"Memmap files already exist – skipping creation.\")\n",
    "        return save_X_path, save_y_path\n",
    "\n",
    "    X_mm = np.memmap(save_X_path, dtype=np.float16, mode=\"w+\",\n",
    "                     shape=(n, h, w, 3))\n",
    "    y_mm = np.memmap(save_y_path, dtype=np.float32, mode=\"w+\",\n",
    "                     shape=(n,))\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image {i} is None\")\n",
    "        resized = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "        X_mm[i] = (resized.astype(np.float32) / 255.0).astype(np.float16)\n",
    "        y_mm[i] = float(labels[i][\"age\"])\n",
    "\n",
    "        if (i+1) % 1000 == 0 or (i+1) == n:\n",
    "            print(f\" Processed {i+1}/{n} images\", end=\"\\r\")\n",
    "\n",
    "    del X_mm, y_mm\n",
    "    gc.collect()\n",
    "    print(\"\\nMemmap creation finished.\")\n",
    "    return save_X_path, save_y_path\n",
    "\n",
    "\n",
    "def load_and_split_from_memmap(X_path, y_path, n_samples,\n",
    "                               target_size=(160,160), normalize_01=True,\n",
    "                               random_seed=42, age_bins=None,\n",
    "                               save_split_info=True,\n",
    "                               split_info_path=\"./dataset_split/dataset_split_info.pkl\"):\n",
    "    \"\"\"\n",
    "    Load memmaps, perform stratified split, standardise ages,\n",
    "    and return a dict with all objects (memmap views – no RAM copy).\n",
    "    \"\"\"\n",
    "\n",
    "    # cleanup old globals (safety)\n",
    "    for name in [\"X\",\"X_tmp\",\"X_train\",\"X_val\",\"X_test\",\n",
    "                 \"dbg_X\",\"dbg_y\",\"dbg_w\"]:\n",
    "        globals().pop(name, None)\n",
    "    gc.collect()\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    NORMALIZE_01 = normalize_01\n",
    "    AGE_BINS = age_bins or [0,5,12,18,30,45,60,80,200]\n",
    "\n",
    "    #  read-only memmaps\n",
    "    X_all = np.memmap(X_path, dtype=np.float16, mode=\"r\",\n",
    "                      shape=(n_samples, target_size[1], target_size[0], 3))\n",
    "    y_all = np.memmap(y_path, dtype=np.float32, mode=\"r\",\n",
    "                      shape=(n_samples,))\n",
    "\n",
    "    ages = np.array(y_all, dtype=np.float32)          # small – fits in RAM\n",
    "    bins_idx = np.digitize(ages, AGE_BINS, right=False) - 1\n",
    "    idx_all = np.arange(len(ages))\n",
    "\n",
    "    # stratified splits\n",
    "    idx_tmp, idx_test, ages_tmp, ages_test, bins_tmp, bins_test = train_test_split(\n",
    "        idx_all, ages, bins_idx,\n",
    "        test_size=0.15, random_state=random_seed, stratify=bins_idx)\n",
    "\n",
    "    val_ratio = 0.15 / (1.0 - 0.15)\n",
    "    idx_train, idx_val, ages_train, ages_val, bins_train, bins_val = train_test_split(\n",
    "        idx_tmp, ages_tmp, bins_tmp,\n",
    "        test_size=val_ratio, random_state=random_seed, stratify=bins_tmp)\n",
    "\n",
    "    # memmap views (no copy)\n",
    "    X_train = X_all[idx_train]\n",
    "    X_val   = X_all[idx_val]\n",
    "    X_test  = X_all[idx_test]\n",
    "\n",
    "    y_train = ages_train\n",
    "    y_val   = ages_val\n",
    "    y_test  = ages_test\n",
    "\n",
    "    # age standardisation (train stats only)\n",
    "    age_mean = y_train.mean()\n",
    "    age_std  = y_train.std()\n",
    "    y_train_std = (y_train - age_mean) / age_std\n",
    "    y_val_std   = (y_val   - age_mean) / age_std\n",
    "    y_test_std  = (y_test  - age_mean) / age_std\n",
    "\n",
    "    print(f\"Age mean: {age_mean:.2f}, std: {age_std:.2f}\")\n",
    "    print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "    print(\"Bin counts (train):\", Counter(bins_train))\n",
    "    print(\"Bin counts (val):\",   Counter(bins_val))\n",
    "    print(\"Bin counts (test):\",  Counter(bins_test))\n",
    "\n",
    "    # save split info (for later evaluation)\n",
    "    if save_split_info:\n",
    "        split_info = {\n",
    "            \"idx_train\": idx_train,\n",
    "            \"idx_val\":   idx_val,\n",
    "            \"idx_test\":  idx_test,\n",
    "            \"age_mean\":  float(age_mean),\n",
    "            \"age_std\":   float(age_std),\n",
    "            \"y_all\":     ages,\n",
    "            \"AGE_BINS\":  AGE_BINS,\n",
    "            \"RANDOM_SEED\": random_seed\n",
    "        }\n",
    "        os.makedirs(os.path.dirname(split_info_path), exist_ok=True)\n",
    "        with open(split_info_path, \"wb\") as f:\n",
    "            pickle.dump(split_info, f)\n",
    "        print(f\"Split info saved → {split_info_path}\")\n",
    "\n",
    "    return {\n",
    "        \"rng\": rng,\n",
    "        \"NORMALIZE_01\": NORMALIZE_01,\n",
    "        \"AGE_BINS\": AGE_BINS,\n",
    "        \"bins_train\": bins_train,\n",
    "        \"bins_val\":   bins_val,\n",
    "        \"bins_test\":  bins_test,\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\":   X_val,\n",
    "        \"X_test\":  X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\":   y_val,\n",
    "        \"y_test\":  y_test,\n",
    "        \"age_mean\": age_mean,\n",
    "        \"age_std\":  age_std,\n",
    "        \"y_train_std\": y_train_std,\n",
    "        \"y_val_std\":   y_val_std,\n",
    "        \"y_test_std\":  y_test_std\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "475752a147f13a70",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "id": "9aa2e381ad1fba30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:15:49.865373Z",
     "start_time": "2025-10-30T19:15:49.829534Z"
    }
   },
   "source": [
    "def build_model(input_shape=(160,160,3)):\n",
    "    \"\"\"\n",
    "    CNN with BatchNorm, LeakyReLU, SpatialDropout, L2 regularisation.\n",
    "    Output: single linear neuron (standardised age).\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3,3), padding='same', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.Conv2D(32, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.SpatialDropout2D(0.25),\n",
    "\n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.Conv2D(64, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.SpatialDropout2D(0.3),\n",
    "\n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.Conv2D(128, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.SpatialDropout2D(0.35),\n",
    "\n",
    "        # Block 4\n",
    "        layers.Conv2D(256, (3,3), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.SpatialDropout2D(0.4),\n",
    "\n",
    "        # Dense head\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(64, activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(32, activation='relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "\n",
    "        layers.Dense(1, activation='linear', dtype='float32')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=tf.keras.losses.Huber(),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError(name='mae'), 'mse'])\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "aa455a374390132c",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "871f19ec3c626001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:15:55.315083Z",
     "start_time": "2025-10-30T19:15:55.291388Z"
    }
   },
   "source": [
    "def train_model(model, train_gen, val_gen, y_train_std, y_val_std,\n",
    "                batch_size=16, epochs=50,\n",
    "                save_path=\"./best_model/best_model.keras\"):\n",
    "\n",
    "    steps_per_epoch = len(y_train_std) // batch_size\n",
    "    validation_steps = len(y_val_std) // batch_size\n",
    "\n",
    "    print(f\"Training samples : {len(y_train_std)}\")\n",
    "    print(f\"Validation samples: {len(y_val_std)}\")\n",
    "    print(f\"Steps/epoch : {steps_per_epoch}  |  Validation steps: {validation_steps}\")\n",
    "\n",
    "    ckpt = callbacks.ModelCheckpoint(save_path,\n",
    "                                     save_best_only=True,\n",
    "                                     monitor=\"val_mae\",\n",
    "                                     mode=\"min\")\n",
    "    rlr  = callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                       factor=0.5, patience=7,\n",
    "                                       min_lr=1e-6, verbose=1)\n",
    "    es   = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                   patience=15,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(train_gen,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=validation_steps,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=[ckpt, rlr, es],\n",
    "                        verbose=1)\n",
    "    return history"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilities",
   "id": "158db2a4484af8ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:46:25.762114Z",
     "start_time": "2025-10-30T19:46:25.704606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# requires augment_once from the augmentation cell\n",
    "def make_sample_weights(bins):\n",
    "    counts = Counter(bins)\n",
    "    n = len(bins)\n",
    "    K = len(counts)\n",
    "    return np.array([n / (K * counts[b]) for b in bins], dtype=np.float32)\n",
    "\n",
    "def train_batch_generator(X, y, batch_size, weights=None, shuffle=True):\n",
    "    n = len(y)\n",
    "    order = np.arange(n)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(order)\n",
    "        for start in range(0, n, batch_size):\n",
    "            sel = order[start:start + batch_size]\n",
    "            bx = np.empty((len(sel),) + X.shape[1:], dtype=np.float32)\n",
    "            for i, j in enumerate(sel):\n",
    "                img = (X[j] * 255.0).astype(np.uint8)\n",
    "                aug = augment_once(img)   # from your augmentation cell\n",
    "                bx[i] = aug\n",
    "            by = y[sel]\n",
    "            if weights is not None:\n",
    "                bw = weights[sel]\n",
    "                yield bx, by, bw\n",
    "            else:\n",
    "                yield bx, by\n",
    "\n",
    "def val_batch_iterator(X, y, batch_size, normalize=True):\n",
    "    n = len(y)\n",
    "    for start in range(0, n, batch_size):\n",
    "        sel = slice(start, start + batch_size)\n",
    "        bx = X[sel].astype(np.float32)\n",
    "        if not normalize:\n",
    "            bx = (bx * 255.0)\n",
    "        by = y[sel]\n",
    "        yield bx, by\n",
    "\n",
    "def evaluate_model_on_test(model, X_test, y_test_std, age_mean, age_std, history=None, normalize=True, verbose=True):\n",
    "    X_test_array = X_test.astype(np.float32)\n",
    "    y_test_array = y_test_std\n",
    "    test_loss, test_mae, test_mse = model.evaluate(X_test_array, y_test_array, verbose=verbose)\n",
    "    y_pred_std = model.predict(X_test_array, verbose=0)\n",
    "    y_pred_raw = y_pred_std * age_std + age_mean\n",
    "    y_test_raw = y_test_array * age_std + age_mean\n",
    "    raw_mae = np.mean(np.abs(y_pred_raw.flatten() - y_test_raw.flatten()))\n",
    "    raw_mse = np.mean((y_pred_raw.flatten() - y_test_raw.flatten())**2)\n",
    "    if verbose:\n",
    "        print(f\"\\n--- Test Set Evaluation ---\")\n",
    "        print(f\"Standardized MAE: {test_mae:.4f}\")\n",
    "        print(f\"Standardized MSE: {test_mse:.4f}\")\n",
    "        print(f\"Raw MAE: {raw_mae:.2f} years\")\n",
    "        print(f\"Raw MSE: {raw_mse:.2f}\")\n",
    "        if history is not None:\n",
    "            print(f\"\\nTraining epochs: {len(history.history['loss'])}\")\n",
    "            print(f\"Min val MAE: {min(history.history['val_mae']):.4f}\")\n",
    "    return {\n",
    "        'test_loss': float(test_loss),\n",
    "        'test_mae': float(test_mae),\n",
    "        'test_mse': float(test_mse),\n",
    "        'raw_mae': float(raw_mae),\n",
    "        'raw_mse': float(raw_mse),\n",
    "    }\n"
   ],
   "id": "250224974a65e93a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "132a82c07e1b8378",
   "metadata": {},
   "source": [
    "**MAIN PIPELINE**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 1. Load raw images\n",
    "# -------------------------------------------------\n",
    "images, labels, df = load_utkface_dataset(\"./data/images\")"
   ],
   "id": "33d741704e67a582"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 2. Visualise raw data\n",
    "# -------------------------------------------------\n",
    "gender_map = {0:\"Male\", 1:\"Female\"}\n",
    "race_map   = {0:\"White\",1:\"Black\",2:\"Asian\",3:\"Indian\",4:\"Other\"}\n",
    "\n",
    "plot_random_samples(images, labels, gender_map, race_map)\n",
    "plot_distribution_charts(df)"
   ],
   "id": "323941382ce1757b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 3. Memmap preprocessing\n",
    "# -------------------------------------------------\n",
    "target_size = (192, 192)\n",
    "memmap_dir  = \"./data/memmap\"\n",
    "size_tag    = f\"{target_size[0]}x{target_size[1]}\"\n",
    "X_path = os.path.join(memmap_dir, f\"X_resized_{size_tag}.dat\")\n",
    "y_path = os.path.join(memmap_dir, f\"y_resized_{size_tag}.dat\")\n",
    "\n",
    "if not (os.path.exists(X_path) and os.path.exists(y_path)):\n",
    "    preprocess_images_to_memmap(images, labels,\n",
    "                                target_size=target_size,\n",
    "                                save_X_path=X_path,\n",
    "                                save_y_path=y_path)\n",
    "else:\n",
    "    print(\"Memmap files already exist – skipping creation.\")\n",
    "\n",
    "n_samples = len(images)\n",
    "\n",
    "preproc = load_and_split_from_memmap(\n",
    "    X_path=X_path, y_path=y_path, n_samples=n_samples,\n",
    "    target_size=target_size, normalize_01=True)\n",
    "\n",
    "# unpack\n",
    "rng           = preproc[\"rng\"]\n",
    "NORMALIZE_01  = preproc[\"NORMALIZE_01\"]\n",
    "AGE_BINS      = preproc[\"AGE_BINS\"]\n",
    "bins_train    = preproc[\"bins_train\"]\n",
    "bins_val      = preproc[\"bins_val\"]\n",
    "bins_test     = preproc[\"bins_test\"]\n",
    "X_train, X_val, X_test = preproc[\"X_train\"], preproc[\"X_val\"], preproc[\"X_test\"]\n",
    "y_train, y_val, y_test = preproc[\"y_train\"], preproc[\"y_val\"], preproc[\"y_test\"]\n",
    "y_train_std = preproc[\"y_train_std\"]\n",
    "y_val_std   = preproc[\"y_val_std\"]\n",
    "y_test_std  = preproc[\"y_test_std\"]\n",
    "age_mean    = preproc[\"age_mean\"]\n",
    "age_std     = preproc[\"age_std\"]\n",
    "\n",
    "# visualise stratified splits\n",
    "plot_age_bin_distribution(bins_train, bins_val, bins_test, AGE_BINS)"
   ],
   "id": "b27fe5c6dc4396c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 4. Augmentation seed\n",
    "# -------------------------------------------------\n",
    "set_augment_seed(rng, NORMALIZE_01)"
   ],
   "id": "f13cd69102e70441"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 5. Sample weighting\n",
    "# -------------------------------------------------\n",
    "train_weights = make_sample_weights(bins_train)\n",
    "print(\"Example weights (first 10):\", train_weights[:10])\n",
    "plot_avg_sample_weight_per_bin(train_weights, bins_train, AGE_BINS)"
   ],
   "id": "59e1f85e31eff5dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 6. Batch generators\n",
    "# -------------------------------------------------\n",
    "batch_size = 16\n",
    "train_gen = train_batch_generator(X_train, y_train_std,\n",
    "                                 batch_size=batch_size,\n",
    "                                 weights=train_weights)\n",
    "val_gen   = val_batch_iterator(X_val, y_val_std,\n",
    "                               batch_size=batch_size)\n",
    "\n",
    "# preview a batch\n",
    "dbg_batch = next(train_gen)\n",
    "if len(dbg_batch) == 3:\n",
    "    dbg_X, dbg_y_std, _ = dbg_batch\n",
    "else:\n",
    "    dbg_X, dbg_y_std = dbg_batch\n",
    "dbg_y_raw = y_train[:len(dbg_y_std)]          # raw ages for caption\n",
    "plot_augmented_samples(dbg_X, dbg_y_raw)"
   ],
   "id": "d39d82e2ba57db1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 7. Build & compile model\n",
    "# -------------------------------------------------\n",
    "model = build_model(input_shape=target_size + (3,))\n",
    "model.summary()"
   ],
   "id": "d5d0f60748ed1e1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 8. Train\n",
    "# -------------------------------------------------\n",
    "history = train_model(model, train_gen, val_gen,\n",
    "                      y_train_std, y_val_std,\n",
    "                      batch_size=batch_size, epochs=50)\n",
    "\n",
    "plot_training_history(history)"
   ],
   "id": "f3ac1fdd4c3eed2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# -------------------------------------------------\n",
    "# 9. Test evaluation (standardised + raw)\n",
    "# -------------------------------------------------\n",
    "test_metrics = evaluate_model_on_test(\n",
    "    model, X_test, y_test_std,\n",
    "    age_mean, age_std,\n",
    "    history=history, verbose=True)\n",
    "\n",
    "print(\"\\nFinal test metrics dict:\")\n",
    "print(test_metrics)"
   ],
   "id": "74ad552884578b31"
  },
  {
   "cell_type": "markdown",
   "id": "5dbde4d7d10a95fd",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67400a81b0486ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR   = \"data/images\"\n",
    "MODEL_PATH  = \"best_model/best_model.keras\"\n",
    "OUTPUT_DIR  = \"evaluation\"\n",
    "RANDOM_SEED = 84\n",
    "TARGET_SIZE = (192,192)\n",
    "NORMALIZE_01 = True\n",
    "BATCH_SIZE   = 32\n",
    "AGE_BINS     = [0,5,12,18,30,45,60,80,200]\n",
    "SHOW_WORST_N = 8\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- logging tee ----------\n",
    "log_path = os.path.join(OUTPUT_DIR, \"run_log.txt\")\n",
    "_log_file = open(log_path, \"w\", encoding=\"utf-8\")\n",
    "class Tee:\n",
    "    def __init__(self, *streams): self.streams = streams\n",
    "    def write(self, data):\n",
    "        for s in self.streams:\n",
    "            try: s.write(data)\n",
    "            except: pass\n",
    "    def flush(self):\n",
    "        for s in self.streams:\n",
    "            try: s.flush()\n",
    "            except: pass\n",
    "\n",
    "_original_stdout = sys.stdout\n",
    "_original_stderr = sys.stderr\n",
    "sys.stdout = Tee(_original_stdout, _log_file)\n",
    "sys.stderr = Tee(_original_stderr, _log_file)\n",
    "\n",
    "def _cleanup():\n",
    "    sys.stdout = _original_stdout\n",
    "    sys.stderr = _original_stderr\n",
    "    _log_file.flush(); _log_file.close()\n",
    "atexit.register(_cleanup)\n",
    "\n",
    "logger = logging.getLogger(\"evaluate_logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.handlers:\n",
    "    fh = logging.FileHandler(log_path, encoding=\"utf-8\")\n",
    "    ch = logging.StreamHandler(_original_stdout)\n",
    "    fmt = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "                            \"%Y-%m-%d %H:%M:%S\")\n",
    "    fh.setFormatter(fmt); ch.setFormatter(fmt)\n",
    "    logger.addHandler(fh); logger.addHandler(ch)\n",
    "\n",
    "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "logger.info(\"Evaluation start – log → %s\", log_path)\n",
    "\n",
    "# ---------- helper ----------\n",
    "def parse_filename_meta(fname):\n",
    "    base = os.path.splitext(fname)[0]\n",
    "    parts = base.split(\"_\")\n",
    "    if len(parts) < 3: return None\n",
    "    try:\n",
    "        age, gender, race = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "    except: return None\n",
    "    return {\"filename\":fname, \"age\":age, \"gender\":gender, \"race\":race}\n",
    "\n",
    "# ---------- 1. load model ----------\n",
    "logger.info(\"Loading model %s\", MODEL_PATH)\n",
    "model = load_model(MODEL_PATH)\n",
    "_dummy = np.zeros((1, TARGET_SIZE[1], TARGET_SIZE[0], 3), dtype=np.float32)\n",
    "if NORMALIZE_01: _dummy /= 255.0\n",
    "model.predict(_dummy, verbose=0)        # ensure built\n",
    "\n",
    "# ---------- 2. load test memmap ----------\n",
    "with open(\"dataset_split/dataset_split_info.pkl\", \"rb\") as f:\n",
    "    split_info = pickle.load(f)\n",
    "idx_test   = split_info[\"idx_test\"]\n",
    "age_mean   = split_info[\"age_mean\"]\n",
    "age_std    = split_info[\"age_std\"]\n",
    "\n",
    "size_tag = f\"{TARGET_SIZE[0]}x{TARGET_SIZE[1]}\"\n",
    "X_path = f\"data/memmap/X_resized_{size_tag}.dat\"\n",
    "y_path = f\"data/memmap/y_resized_{size_tag}.dat\"\n",
    "\n",
    "n_samples = len(split_info[\"idx_train\"]) + len(split_info[\"idx_val\"]) + len(split_info[\"idx_test\"])\n",
    "X_all = np.memmap(X_path, dtype=np.float16, mode=\"r\",\n",
    "                  shape=(n_samples, TARGET_SIZE[1], TARGET_SIZE[0], 3))\n",
    "y_all = np.memmap(y_path, dtype=np.float32, mode=\"r\", shape=(n_samples,))\n",
    "\n",
    "X_test = X_all[idx_test].astype(np.float32)\n",
    "y_real = np.array(y_all[idx_test], dtype=np.float32)\n",
    "y_std  = (y_real - age_mean) / age_std\n",
    "logger.info(\"Test set loaded – %d images\", X_test.shape[0])\n",
    "\n",
    "# reconstruct metadata (for CSV & bias analysis)\n",
    "meta_list = []\n",
    "for i in idx_test:\n",
    "    fname = sorted(os.listdir(IMAGE_DIR))[i]\n",
    "    meta = parse_filename_meta(fname)\n",
    "    if meta: meta_list.append(meta)\n",
    "meta_df = pd.DataFrame(meta_list)\n",
    "\n",
    "# ---------- 3. predict ----------\n",
    "logger.info(\"Predicting …\")\n",
    "y_pred_std = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1).flatten()\n",
    "y_pred = y_pred_std * age_std + age_mean\n",
    "\n",
    "mae = mean_absolute_error(y_real, y_pred)\n",
    "mse = mean_squared_error(y_real, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2  = r2_score(y_real, y_pred)\n",
    "\n",
    "logger.info(\"=== Metrics (real ages) ===\")\n",
    "logger.info(\"MAE  : %.4f years\", mae)\n",
    "logger.info(\"MSE  : %.4f\", mse)\n",
    "logger.info(\"RMSE : %.4f\", rmse)\n",
    "logger.info(\"R²   : %.4f\", r2)\n",
    "\n",
    "# ---------- 4. CSV ----------\n",
    "results_df = meta_df.copy()\n",
    "results_df[\"true_age_real\"] = y_real\n",
    "results_df[\"true_age_std\"]  = y_std\n",
    "results_df[\"pred_age_real\"] = y_pred\n",
    "results_df[\"pred_age_std\"]  = y_pred_std\n",
    "results_df[\"error_real\"]    = y_pred - y_real\n",
    "results_df[\"abs_error_real\"]= np.abs(results_df[\"error_real\"])\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"test_predictions.csv\")\n",
    "results_df.to_csv(csv_path, index=False)\n",
    "logger.info(\"Saved predictions → %s\", csv_path)\n",
    "\n",
    "# ---------- 5. Plot helpers ----------\n",
    "def savefig(pth):\n",
    "    plt.savefig(pth, dpi=150, bbox_inches=\"tight\")\n",
    "    logger.info(\"Saved plot → %s\", pth)\n",
    "    plt.close()\n",
    "\n",
    "# ---- scatter ----\n",
    "lims = [0, max(y_real.max(), y_pred.max())+5]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_real, y_pred, s=20, alpha=0.5, edgecolor=\"w\")\n",
    "plt.plot(lims, lims, 'k--', alpha=0.7, label=\"Perfect\")\n",
    "plt.xlim(lims); plt.ylim(lims)\n",
    "plt.xlabel(\"True Age\"); plt.ylabel(\"Predicted Age\")\n",
    "plt.title(\"Predicted vs True Age\")\n",
    "plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"pred_vs_true_scatter.png\"))\n",
    "\n",
    "# ---- hexbin ----\n",
    "plt.figure(figsize=(7,7))\n",
    "hb = plt.hexbin(y_real, y_pred, gridsize=50, cmap=\"Reds\", mincnt=1)\n",
    "cb = plt.colorbar(hb); cb.set_label(\"Counts\")\n",
    "plt.plot(lims, lims, 'k--', alpha=0.7)\n",
    "plt.xlim(lims); plt.ylim(lims)\n",
    "plt.xlabel(\"True Age\"); plt.ylabel(\"Predicted Age\")\n",
    "plt.title(\"Predicted vs True (density)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"pred_vs_true_density.png\"))\n",
    "\n",
    "# ---- residuals ----\n",
    "residuals = y_pred - y_real\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(y_real, residuals, alpha=0.5, s=20, edgecolor=\"w\")\n",
    "plt.axhline(0, color='k', linestyle='--', alpha=0.6)\n",
    "plt.xlabel(\"True Age\"); plt.ylabel(\"Residual (Pred-True)\")\n",
    "plt.title(\"Residuals vs True Age\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"residuals_vs_age.png\"))\n",
    "\n",
    "# ---- residual histogram ----\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(residuals, bins=40, kde=True, color=\"#FF8A65\")\n",
    "plt.xlabel(\"Residual\"); plt.ylabel(\"Count\")\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"residual_histogram.png\"))\n",
    "\n",
    "# ---- MAE per age bin ----\n",
    "bin_idx = np.digitize(y_real, AGE_BINS, right=False) - 1\n",
    "bin_labels = [f\"{AGE_BINS[i]}–{AGE_BINS[i+1]-1}\" if i<len(AGE_BINS)-2 else f\"{AGE_BINS[i]}+\"\n",
    "              for i in range(len(AGE_BINS)-1)]\n",
    "bin_mae = [np.mean(np.abs(y_pred[bin_idx==i] - y_real[bin_idx==i]))\n",
    "           if np.any(bin_idx==i) else np.nan\n",
    "           for i in range(len(AGE_BINS)-1)]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=bin_labels, y=bin_mae, palette=\"rocket\")\n",
    "plt.xlabel(\"Age Bin\"); plt.ylabel(\"MAE (years)\")\n",
    "plt.title(\"MAE per Age Bin\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"mae_per_age_bin.png\"))\n",
    "\n",
    "# ---- worst predictions ----\n",
    "worst_idx = np.argsort(-results_df[\"abs_error_real\"].values)[:SHOW_WORST_N]\n",
    "plt.figure(figsize=(12,6))\n",
    "for i, idx in enumerate(worst_idx):\n",
    "    ax = plt.subplot(2, (SHOW_WORST_N+1)//2, i+1)\n",
    "    img = X_test[idx]\n",
    "    if NORMALIZE_01: img = np.clip(img,0,1)\n",
    "    ax.imshow(img)\n",
    "    true = results_df.loc[idx, \"true_age_real\"]\n",
    "    pred = results_df.loc[idx, \"pred_age_real\"]\n",
    "    err  = results_df.loc[idx, \"abs_error_real\"]\n",
    "    ax.set_title(f\"T:{true:.1f} / P:{pred:.1f}\\nΔ={err:.1f}\", fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\"Hardest Predictions\", weight=\"bold\")\n",
    "savefig(os.path.join(OUTPUT_DIR, \"hardest_predictions.png\"))\n",
    "\n",
    "# ---- summary txt ----\n",
    "summary_path = os.path.join(OUTPUT_DIR, \"results_summary.txt\")\n",
    "with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Test Set Summary (Real Ages) ===\\n\")\n",
    "    f.write(f\"Images : {len(y_real)}\\n\")\n",
    "    f.write(f\"MAE    : {mae:.6f} years\\n\")\n",
    "    f.write(f\"MSE    : {mse:.6f}\\n\")\n",
    "    f.write(f\"RMSE   : {rmse:.6f}\\n\")\n",
    "    f.write(f\"R²     : {r2:.6f}\\n\")\n",
    "logger.info(\"Summary → %s\", summary_path)\n",
    "\n",
    "# ---- demographic bias ----\n",
    "gender_map = {0:\"Male\",1:\"Female\"}\n",
    "race_map   = {0:\"White\",1:\"Black\",2:\"Asian\",3:\"Indian\",4:\"Other\"}\n",
    "demo_df = results_df.copy()\n",
    "if \"gender\" in meta_df.columns and \"race\" in meta_df.columns:\n",
    "    demo_df[\"gender\"] = meta_df[\"gender\"]\n",
    "    demo_df[\"race\"]   = meta_df[\"race\"]\n",
    "demo_df[\"gender_str\"] = demo_df[\"gender\"].map(gender_map).fillna(demo_df[\"gender\"].astype(str))\n",
    "demo_df[\"race_str\"]   = demo_df[\"race\"].map(race_map).fillna(demo_df[\"race\"].astype(str))\n",
    "\n",
    "gender_stats = demo_df.groupby(\"gender_str\").agg(\n",
    "    MAE=(\"abs_error_real\",\"mean\"),\n",
    "    RMSE=(\"abs_error_real\", lambda x: math.sqrt(np.mean(x**2))),\n",
    "    Count=(\"abs_error_real\",\"count\")\n",
    ").reset_index()\n",
    "gender_stats.to_csv(os.path.join(OUTPUT_DIR, \"gender_error_stats.csv\"), index=False)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.barplot(data=gender_stats, x=\"gender_str\", y=\"MAE\",\n",
    "            palette=[\"#F9C5D5\",\"#F48FB1\"])\n",
    "plt.title(\"MAE by Gender\"); plt.xlabel(\"Gender\"); plt.ylabel(\"MAE (years)\")\n",
    "savefig(os.path.join(OUTPUT_DIR, \"mae_by_gender.png\"))\n",
    "\n",
    "race_stats = demo_df.groupby(\"race_str\").agg(\n",
    "    MAE=(\"abs_error_real\",\"mean\"),\n",
    "    RMSE=(\"abs_error_real\", lambda x: math.sqrt(np.mean(x**2))),\n",
    "    Count=(\"abs_error_real\",\"count\")\n",
    ").reset_index()\n",
    "race_stats.to_csv(os.path.join(OUTPUT_DIR, \"race_error_stats.csv\"), index=False)\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=race_stats, x=\"race_str\", y=\"MAE\", palette=\"mako\")\n",
    "plt.title(\"MAE by Race\"); plt.xlabel(\"Race\"); plt.ylabel(\"MAE (years)\")\n",
    "plt.xticks(rotation=15)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"mae_by_race.png\"))\n",
    "\n",
    "# ---- calibration per bin ----\n",
    "demo_df[\"age_bin\"] = pd.cut(demo_df[\"true_age_real\"], bins=AGE_BINS,\n",
    "                            include_lowest=True, right=False,\n",
    "                            labels=bin_labels)\n",
    "calib = demo_df.groupby(\"age_bin\", observed=False).agg(\n",
    "    true_mean=(\"true_age_real\",\"mean\"),\n",
    "    pred_mean=(\"pred_age_real\",\"mean\"),\n",
    "    count=(\"true_age_real\",\"count\")\n",
    ").reset_index()\n",
    "\n",
    "max_age = max(calib[\"true_mean\"].max(), calib[\"pred_mean\"].max()) + 5\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(calib[\"true_mean\"], calib[\"pred_mean\"],\n",
    "            s=np.clip(calib[\"count\"]*2,10,300),\n",
    "            c=calib[\"count\"], cmap=\"Reds\", alpha=0.8,\n",
    "            edgecolors=\"w\", linewidths=0.5)\n",
    "plt.plot([0,max_age],[0,max_age],\"k--\",alpha=0.6)\n",
    "plt.xlabel(\"Mean True Age (bin)\"); plt.ylabel(\"Mean Predicted Age (bin)\")\n",
    "plt.title(\"Calibration per Age Bin\")\n",
    "cb = plt.colorbar(); cb.set_label(\"Samples\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "savefig(os.path.join(OUTPUT_DIR, \"calibration_age_bin.png\"))\n",
    "\n",
    "print(\"\\n=== Evaluation finished – all files in\", OUTPUT_DIR, \"===\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
